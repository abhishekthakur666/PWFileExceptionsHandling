{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGFp6meNbVKswjhId6fnRe"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice."
      ],
      "metadata": {
        "id": "uC8HuNiyUSY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multithreading vs. Multiprocessing\n",
        "\n",
        "# Multithreading is preferable when:\n",
        "\n",
        "#1. I/O-bound tasks:  When your program spends a significant amount of time waiting for external resources like network requests, disk operations, or user input.  Threads can overlap these wait times, making your program more responsive.  Because the Global Interpreter Lock (GIL) in CPython allows only one thread to hold control of the Python interpreter at any one time, true parallelism isn't achieved for CPU-bound tasks. However, in I/O-bound tasks, threads are still beneficial because they can switch to another task while waiting.\n",
        "\n",
        "#2. Shared memory access: Threads share the same memory space, which makes communication between them very efficient. If your application requires frequent data exchange between different parts of your code, threading can be faster than multiprocessing, which necessitates inter-process communication mechanisms (IPC).\n",
        "\n",
        "#3. Simpler implementation (sometimes): In some cases, threading can lead to less complex code compared to multiprocessing because of the shared memory model.\n",
        "\n",
        "# Multiprocessing is preferable when:\n",
        "\n",
        "#1. CPU-bound tasks: When your program is computationally intensive, relying heavily on the CPU for calculations.  Multiprocessing bypasses the GIL limitation, allowing multiple processes to utilize multiple CPU cores effectively.  This is the greatest advantage of multiprocessing.  For CPU intensive tasks, multiprocessing can significantly reduce execution time.\n",
        "\n",
        "#2. Avoiding GIL limitations: The GIL is a major hurdle in CPython for CPU-bound, multi-threaded applications.  Multiprocessing provides true parallelism.\n",
        "\n",
        "#3. Increased stability: Since processes are isolated from each other, a crash in one process generally won't affect the others. This contributes to application stability.\n",
        "\n",
        "#4. Numerical computations: For applications relying heavily on numerical computations (e.g., scientific computing, data analysis), libraries like NumPy, SciPy, and others are often optimized for multiprocessing.\n",
        "\n"
      ],
      "metadata": {
        "id": "LDKow6AHUVfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Describe what a process pool is and how it helps in managing multiple processes efficiently."
      ],
      "metadata": {
        "id": "kazf2WO1Up-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# A process pool is a collection of worker processes that are managed by a central process.  It provides a convenient way to distribute tasks across multiple CPU cores, significantly improving performance for CPU-bound operations.  The process pool manages the creation, allocation, and termination of worker processes, and provides a simple interface for submitting tasks.  Instead of manually creating and managing individual processes, developers use the process pool to efficiently distribute tasks, thereby avoiding the overhead of frequent process creation and destruction.\n",
        "\n",
        "# Here's how it helps:\n",
        "\n",
        "#1. Efficient resource utilization:  The process pool creates a fixed number of worker processes at the beginning. This avoids the overhead of creating and destroying processes for each task.  The worker processes are then reused for subsequent tasks, leading to better resource utilization.\n",
        "#2. Simplified task distribution: The process pool provides a simple API for submitting tasks.  Tasks can be submitted to the pool, which then assigns them to available worker processes.  The pool handles task scheduling, ensuring that processes are kept busy.\n",
        "#3. Controlled parallelism:  The process pool allows controlling the degree of parallelism by specifying the number of worker processes to create.  This allows adapting to different hardware configurations and workloads.\n",
        "#4. Enhanced performance: By leveraging multiple CPU cores and efficiently managing worker processes, the process pool significantly improves the performance of CPU-bound tasks, leading to reduced execution times.  This is especially true for computationally intensive applications.\n",
        "#5. Simplified error handling: Centralized management makes it easier to handle exceptions or errors from individual worker processes.  The pool can provide mechanisms for capturing and managing errors in a consistent way."
      ],
      "metadata": {
        "id": "Hn5lXPzYUsC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Explain what multiprocessing is and why it is used in Python programs."
      ],
      "metadata": {
        "id": "heQ2KjtJU6Eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Multiprocessing in Python is a technique that allows you to leverage multiple CPU cores to execute tasks concurrently.  It's fundamentally different from multithreading because each process runs in its own memory space, completely independent of other processes. This independence offers several advantages, particularly for CPU-bound tasks.\n",
        "\n",
        "#1. True Parallelism: Unlike multithreading in CPython, which is limited by the Global Interpreter Lock (GIL), multiprocessing bypasses the GIL and enables true parallelism. This means multiple processes can genuinely execute simultaneously on multiple CPU cores, leading to significant performance improvements for computationally intensive tasks.\n",
        "\n",
        "#2. CPU-Bound Tasks: Multiprocessing excels at CPU-bound tasks – operations that require substantial processing power and consume a lot of CPU time.  Examples include complex mathematical calculations, data processing, simulations, or anything that doesn't spend much time waiting for external resources.\n",
        "\n",
        "#3. Isolation and Stability:  Processes are isolated from each other. If one process crashes or encounters an error, it typically doesn't affect other processes. This increases the overall stability and robustness of applications, especially large or complex ones.\n",
        "\n",
        "#4. Improved Resource Utilization: By distributing tasks across multiple processes, you can effectively use all available CPU cores. This leads to faster execution times and improved resource utilization, especially on multi-core machines.\n",
        "\n",
        "#5. Numerical Computations: Many numerical computing libraries are optimized for multiprocessing, allowing efficient parallelization of tasks that involve large datasets or complex calculations. Libraries like NumPy often have built-in functions that facilitate the distribution of work across multiple cores.\n",
        "\n",
        "#In summary, multiprocessing is crucial in Python when you need true parallelism for CPU-bound tasks to improve performance, stability, and resource utilization.\n"
      ],
      "metadata": {
        "id": "te78HBubU7Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock."
      ],
      "metadata": {
        "id": "XZkEdrtIVMnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Shared resources\n",
        "my_list = []\n",
        "lock = threading.Lock()\n",
        "\n",
        "def add_number():\n",
        "    for _ in range(5):\n",
        "        lock.acquire()  # Acquire the lock before modifying the list\n",
        "        try:\n",
        "            number = random.randint(1, 100)\n",
        "            my_list.append(number)\n",
        "            print(f\"Added {number} to the list. List: {my_list}\")\n",
        "            time.sleep(0.5)  # Simulate some work\n",
        "        finally:\n",
        "            lock.release()  # Release the lock\n",
        "\n",
        "def remove_number():\n",
        "    for _ in range(5):\n",
        "        lock.acquire()\n",
        "        try:\n",
        "            if my_list:  # Check if the list is not empty\n",
        "              number = my_list.pop(0)  # Remove from the beginning of the list\n",
        "              print(f\"Removed {number} from the list. List: {my_list}\")\n",
        "              time.sleep(0.3) # Simulate some work\n",
        "            else:\n",
        "              print(\"List is empty, nothing to remove\")\n",
        "        finally:\n",
        "            lock.release()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    thread1 = threading.Thread(target=add_number)\n",
        "    thread2 = threading.Thread(target=remove_number)\n",
        "\n",
        "    thread1.start()\n",
        "    thread2.start()\n",
        "\n",
        "    thread1.join()\n",
        "    thread2.join()\n",
        "\n",
        "    print(\"Final list:\", my_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20BYqOk-VgAj",
        "outputId": "e3f7f072-118f-4327-d11d-f4eb66f596eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 74 to the list. List: [74]\n",
            "Added 81 to the list. List: [74, 81]\n",
            "Added 87 to the list. List: [74, 81, 87]\n",
            "Added 41 to the list. List: [74, 81, 87, 41]\n",
            "Added 52 to the list. List: [74, 81, 87, 41, 52]\n",
            "Removed 74 from the list. List: [81, 87, 41, 52]\n",
            "Removed 81 from the list. List: [87, 41, 52]\n",
            "Removed 87 from the list. List: [41, 52]\n",
            "Removed 41 from the list. List: [52]\n",
            "Removed 52 from the list. List: []\n",
            "Final list: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2PJ_ayQdVnzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Describe the methods and tools available in Python for safely sharing data between threads and processes."
      ],
      "metadata": {
        "id": "bI_eKrbbV0Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Methods and Tools for Safe Data Sharing\n",
        "\n",
        "# 1. Threading (within a process):\n",
        "\n",
        "# a) Locks (threading.Lock):\n",
        "#    - Prevent race conditions by allowing only one thread to access a shared resource at a time.\n",
        "#    - Example: The provided code demonstrates the use of threading.Lock to protect the my_list.\n",
        "\n",
        "# b) RLocks (threading.RLock):\n",
        "#    - Allow a thread to acquire the same lock multiple times without deadlocking itself.  Useful when a thread might need to acquire the lock in different sections of its code.\n",
        "\n",
        "# c) Semaphores (threading.Semaphore):\n",
        "#    - Control access to a shared resource by a limited number of threads.  Useful for limiting the number of threads that can access a resource simultaneously (e.g., a database connection pool).\n",
        "\n",
        "# d) Events (threading.Event):\n",
        "#    - Provide a simple mechanism for threads to communicate with each other, often to signal that an event has occurred or a condition has been met.\n",
        "\n",
        "# e) Conditions (threading.Condition):\n",
        "#    - Enable threads to wait for a specific condition to become true. More sophisticated than Events; threads can wait for specific predicates.\n",
        "\n",
        "# f) Queues (queue.Queue):\n",
        "#    - Thread-safe queues for passing data between threads without the need for explicit locking.\n",
        "\n",
        "# 2. Multiprocessing (separate processes):\n",
        "\n",
        "# a) Queues (multiprocessing.Queue):\n",
        "#    - Similar to threading.Queue, but designed for inter-process communication (IPC).\n",
        "#    - Safe for sharing data between processes.\n",
        "\n",
        "# b) Pipes (multiprocessing.Pipe):\n",
        "#    - Create a two-way communication channel between two processes.\n",
        "\n",
        "# c) Value and Array (multiprocessing.Value, multiprocessing.Array):\n",
        "#    - Shared memory objects that allow for efficient data sharing between processes.\n",
        "#    - Data must be of a shared type (e.g., integers, floats).\n",
        "\n",
        "# d) Managers (multiprocessing.Manager):\n",
        "#    - Provide a way to create shared objects (lists, dictionaries, etc.) that can be accessed by multiple processes.\n",
        "#    - Objects are stored in a separate server process to coordinate access safely.\n",
        "\n",
        "# e) Shared Memory (multiprocessing.shared_memory):\n",
        "#     - Allows creating and using shared memory blocks directly.\n",
        "#     - Provides fine-grained control but can be more complex to use.\n",
        "\n",
        "#Choosing the right method depends on the nature of your task:\n",
        "\n",
        "#   - For simple synchronization: Locks, RLocks, Semaphores\n",
        "#   - For signaling events: Events, Conditions\n",
        "#   - For data transfer: Queues (in both threads and processes)\n",
        "#   - For shared state within a process: Values and Arrays (less common)\n",
        "\n",
        "# Best Practices:\n",
        "\n",
        "# - Minimize shared data:  Reduce the amount of data that needs to be shared between threads/processes.\n",
        "# - Use thread-safe data structures:  Employ thread-safe queues or locks when necessary.\n",
        "# - Consider process pools for CPU-bound tasks: For CPU-intensive workloads, use process pools for better scalability and resource usage.\n",
        "# - For IPC in multiprocessing: Queues and Pipes are generally preferred.\n"
      ],
      "metadata": {
        "id": "qOuQihO8V2Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so."
      ],
      "metadata": {
        "id": "rj2DVVDvV_Kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Importance of Exception Handling in Concurrent Programs\n",
        "\n",
        "# In concurrent programs (using threads or processes), exceptions can be especially tricky because multiple execution paths can occur simultaneously.  If an exception occurs in one thread or process and isn't handled properly, it can lead to various issues, including:\n",
        "\n",
        "# 1. Resource Leaks:  A thread or process might acquire resources (locks, files, network connections) and fail to release them before crashing.  This leaves the resources unavailable to other parts of the program, potentially causing deadlocks or other problems.\n",
        "# 2. Program Instability:  An unhandled exception in one thread or process could cascade and destabilize the entire application, leading to unpredictable behavior or crashes.\n",
        "# 3. Data Corruption: If an exception happens while multiple threads or processes access shared resources, data corruption might occur.  The shared data could be in an inconsistent state if one thread crashes while modifying it.\n",
        "# 4. Deadlocks: Exceptions can lead to situations where threads or processes are waiting indefinitely for each other, resulting in a program freeze.\n",
        "# 5. Difficult Debugging: Debugging concurrent programs is already complex.  Unhandled exceptions make it even harder to pinpoint the root cause of issues.\n",
        "\n",
        "\n",
        "# Techniques for Handling Exceptions in Concurrent Programs\n",
        "\n",
        "# 1. Try-Except Blocks: The fundamental approach remains the same as in single-threaded programs – using try-except blocks.\n",
        "\n",
        "\n",
        "#       try:\n",
        "#           # Code that might raise an exception\n",
        "#           result = 10 / 0  # Example: Potential ZeroDivisionError\n",
        "#       except ZeroDivisionError as e:\n",
        "#           print(f\"Exception in thread: {e}\")\n",
        "#           # Handle the exception (e.g., log it, return a default value, etc.)\n",
        "#       finally:\n",
        "#           # Always release resources in the finally block\n",
        "#           # ...release locks, close files, etc....\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 2. Thread-Specific Exception Handling:\n",
        "\n",
        "#  Sometimes you might want to handle exceptions differently based on the thread where they occur.  While not always necessary, it can be helpful for specialized error management.\n",
        "\n",
        "\n",
        "# 3. Signaling and Inter-Process Communication (IPC):\n",
        "\n",
        "#  In multiprocess applications, you can use queues or pipes for communication.  If an exception occurs in one process, it can send a message to other processes indicating the error.  This allows for coordinated cleanup or error recovery.\n",
        "\n",
        "\n",
        "# 4. Global Exception Handlers (with Caution):\n",
        "\n",
        "#  Avoid global exception handlers as much as possible. They can mask crucial errors. In some cases, using a dedicated error monitoring system or logging mechanisms might be a better strategy for centralized exception management.  Consider using signals if you must have a broader exception handler.\n",
        "\n",
        "# Example of handling exceptions in multiprocessing (with a queue):\n",
        "\n",
        "\n",
        "import multiprocessing\n",
        "\n",
        "def worker(queue):\n",
        "    try:\n",
        "        # Code that might raise an exception\n",
        "        result = 10 / 0  # Example\n",
        "    except Exception as e:\n",
        "        queue.put(e) # Put the exception in a queue\n",
        "\n",
        "queue = multiprocessing.Queue()\n",
        "process = multiprocessing.Process(target=worker, args=(queue,))\n",
        "process.start()\n",
        "process.join()\n",
        "\n",
        "if not queue.empty():\n",
        "    exception = queue.get()\n",
        "    print(f\"Caught exception in worker process: {exception}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT8fJm-0WWC8",
        "outputId": "002d665b-6b43-4cae-a031-48ab06aabb67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caught exception in worker process: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.Use concurrent.futures.ThreadPoolExecutor to manage the threads."
      ],
      "metadata": {
        "id": "1GRsQS8PXfiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "import math\n",
        "\n",
        "def factorial(n):\n",
        "  \"\"\"Calculates the factorial of a number.\"\"\"\n",
        "  return math.factorial(n)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  numbers = range(1, 11)\n",
        "  with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    results = executor.map(factorial, numbers)\n",
        "\n",
        "  for number, result in zip(numbers, results):\n",
        "    print(f\"The factorial of {number} is {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zB3HHSDXhlA",
        "outputId": "15e2b8e3-8741-4b65-9882-2e301a759af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The factorial of 1 is 1\n",
            "The factorial of 2 is 2\n",
            "The factorial of 3 is 6\n",
            "The factorial of 4 is 24\n",
            "The factorial of 5 is 120\n",
            "The factorial of 6 is 720\n",
            "The factorial of 7 is 5040\n",
            "The factorial of 8 is 40320\n",
            "The factorial of 9 is 362880\n",
            "The factorial of 10 is 3628800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes)."
      ],
      "metadata": {
        "id": "5tPHqo2KXwRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "def square(n):\n",
        "  \"\"\"Computes the square of a number.\"\"\"\n",
        "  time.sleep(0.1)  # Simulate some work\n",
        "  return n * n\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  numbers = list(range(1, 11))\n",
        "  pool_sizes = [2, 4, 8]\n",
        "\n",
        "  for pool_size in pool_sizes:\n",
        "    with multiprocessing.Pool(processes=pool_size) as pool:\n",
        "      start_time = time.time()\n",
        "      results = pool.map(square, numbers)\n",
        "      end_time = time.time()\n",
        "      print(f\"Pool size: {pool_size}, Time taken: {end_time - start_time:.4f} seconds\")\n",
        "      # print(f\"Results: {results}\") # Uncomment if you need to print the results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4YwxOhMXzxK",
        "outputId": "a2597e97-5b54-4877-b394-d88ba145795f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool size: 2, Time taken: 0.6052 seconds\n",
            "Pool size: 4, Time taken: 0.3040 seconds\n",
            "Pool size: 8, Time taken: 0.2038 seconds\n"
          ]
        }
      ]
    }
  ]
}